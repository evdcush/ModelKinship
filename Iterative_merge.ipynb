{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o12O0YjJvvLW"
      },
      "source": [
        "# Iterative Merging with Model Kinship\n",
        "> Our Github [Merge Assistant Toolkit](https://github.com/zjunlp/ModelKinship).\n",
        "\n",
        "> Open in Colab [This Notebook](https://colab.research.google.com/drive/141VAI89emgSIcwkswATEXSEENoAMywTO?usp=sharing)\n",
        "\n",
        "This notebook demonstrates iterative merging using external tools to enhance large language model performance.\n",
        "It leverages the following:\n",
        "\n",
        "- [lm-evaluation-harness by EleutherAI](https://github.com/EleutherAI/lm-evaluation-harness) for providing a comprehensive evaluation framework for large language models.\n",
        "- [mergekit by arcee-ai](https://github.com/arcee-ai/mergekit) for offering an essential toolkit for model merging experiments.\n",
        "\n",
        "We express our gratitude to the contributors of these valuable tools."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Install requirements\n",
        "\n",
        "# @markdown ### Run this section to install the required dependencies and log in to Hugging Face Hub.\n",
        "\n",
        "!git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
        "!pip install -e ./lm-evaluation-harness\n",
        "!git clone https://github.com/zjunlp/ModelKinship.git\n",
        "!pip install -e ./ModelKinship\n",
        "!git clone https://github.com/cg123/mergekit.git\n",
        "!pip install -e ./mergekit\n",
        "!pip install -qU huggingface_hub\n",
        "\n",
        "username = \"xxx\" # @param {\"type\":\"string\"}\n",
        "HF_Token = \"hf_xxxx\" # @param {\"type\":\"string\"}\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(HF_Token)\n",
        "api = HfApi(token=HF_Token)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HK6EceEVeyS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Select Models\n",
        "\n",
        "# @markdown ### Model 1\n",
        "# @markdown Select your first model in huggingface hub.\n",
        "\n",
        "Model_1 = \"openchat/openchat-3.5-1210\" # @param {\"type\":\"string\"}\n",
        "\n",
        "# @markdown ### Model 1\n",
        "# @markdown Select your second model in huggingface hub.\n",
        "\n",
        "Model_2 = \"meta-math/MetaMath-Mistral-7B\" # @param {\"type\":\"string\"}\n",
        "\n",
        "# @markdown ### Similarity metric for Model Kinship\n",
        "# @markdown Select similarity metric for model kinship. Details can be found in our paper.\n",
        "\n",
        "Similarity_metric = \"Pearson Correlation Coefficient\" # @param [\"Pearson Correlation Coefficient\",\"Cosine Similarity\",\"Euclidean Distance\"]\n",
        "# Save config as yaml file\n",
        "with open('config.yaml', 'w', encoding=\"utf-8\") as f:\n",
        "    f.write(yaml_config)\n",
        "\n",
        "cli = \"merge_cal\"\n",
        "cli += \" \" + Model_1\n",
        "cli += \" \" + Model_2\n",
        "\n",
        "\n",
        "# Similarity Metrics\n",
        "if Similarity_metric == \"Euclidean Distance\":\n",
        "    cli += \" ed\"\n",
        "elif Similarity_metric == \"Cosine Similarity\":\n",
        "    cli += \" cs\"\n",
        "elif Similarity_metric == \"Pearson Correlation Coefficient\"\n",
        "    cli += \" pcc\"\n",
        "\n",
        "print(cli)\n",
        "\n",
        "# Calculation\n",
        "!{cli}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yO9AVaNYeuiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Merge Models\n",
        "\n",
        "# @markdown ### Name for the merged model\n",
        "# @markdown Name your merged model.\n",
        "Model_merge = \"Merge_1_1\" # @param {\"type\":\"string\"}\n",
        "\n",
        "# @markdown ### Model 1 (base model)\n",
        "# @markdown Select your first model in huggingface hub.\n",
        "\n",
        "Model_1 = \"openchat/openchat-3.5-1210\" # @param {\"type\":\"string\"}\n",
        "\n",
        "# @markdown ### Model 2\n",
        "# @markdown Select your second model in huggingface hub.\n",
        "\n",
        "Model_2 = \"meta-math/MetaMath-Mistral-7B\" # @param {\"type\":\"string\"}\n",
        "\n",
        "config = f\"\"\"\n",
        "slices:\n",
        "  - sources:\n",
        "      - model: {Model_1}\n",
        "        layer_range: [0, 32]\n",
        "      - model: {Model_2}\n",
        "        layer_range: [0, 32]\n",
        "merge_method: slerp\n",
        "base_model: {Model_1}\n",
        "parameters:\n",
        "  t:\n",
        "    - filter: self_attn\n",
        "      value: [0, 0.5, 0.3, 0.7, 1]\n",
        "    - filter: mlp\n",
        "      value: [1, 0.5, 0.7, 0.3, 0]\n",
        "    - value: 0.5\n",
        "dtype: bfloat16\n",
        "\"\"\"\n",
        "\n",
        "with open('config.yaml', 'w', encoding=\"utf-8\") as f:\n",
        "    f.write(config)\n",
        "\n",
        "!mergekit-yaml config.yaml merge --copy-tokenizer --allow-crimes --out-shard-size 1B --lazy-unpickle"
      ],
      "metadata": {
        "cellView": "form",
        "id": "b63EhHIFm7Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Recycle Models\n",
        "\n",
        "# @markdown ### Run this section to upload merged model.\n",
        "\n",
        "from huggingface_hub import ModelCard, ModelCardData\n",
        "from jinja2 import Template\n",
        "\n",
        "template_text = \"\"\"\n",
        "---\n",
        "license: apache-2.0\n",
        "tags:\n",
        "{%- for model in models %}\n",
        "- {{ model }}\n",
        "{%- endfor %}\n",
        "---\n",
        "\n",
        "{%- for model in models %}\n",
        "* [{{ model }}](https://huggingface.co/{{ model }})\n",
        "{%- endfor %}\n",
        "\"\"\"\n",
        "\n",
        "jinja_template = Template(template_text.strip())\n",
        "\n",
        "data = yaml.safe_load(yaml_config)\n",
        "models = [data[\"slices\"][i][\"sources\"][0][\"model\"] for i in range(len(data[\"slices\"]))]\n",
        "content = jinja_template.render(\n",
        "    model_name=Model_name,\n",
        "    models=models,\n",
        "    username=username,\n",
        ")\n",
        "\n",
        "# Save the model card\n",
        "card = ModelCard(content)\n",
        "card.save('merge/README.md')\n",
        "\n",
        "api.create_repo(\n",
        "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
        "    repo_type=\"model\"\n",
        ")\n",
        "api.upload_folder(\n",
        "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
        "    folder_path=\"merge\",\n",
        ")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O_xv1W2ep3WT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}